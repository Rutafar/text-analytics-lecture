{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class of Week 7\n",
    "Content:  \n",
    "1. TF-IDF  \n",
    "2. Singular Value Decomposition  \n",
    "3. Latent Semantic Indexing\n",
    "4. Latent Dirichlet Allocation  \n",
    "5. Open Questions and Project Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Term-Frequency-Inverse-Document Frequency.  \n",
    "Bag-of-words approach that gives more weight to 'important' words.  \n",
    "Useful resources:  \n",
    "https://www.youtube.com/watch?v=4vT4fzjkGCQ  \n",
    "https://www.youtube.com/watch?v=hXNbFNCgPfY  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog sits on the table', 'the cat sits on the sofa']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two documents.\n",
    "docs = ['the dog sits on the table',\n",
    "        'the cat sits on the sofa']\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'dog': 1, 'on': 1, 'sits': 1, 'table': 1, 'the': 2}),\n",
       " Counter({'cat': 1, 'on': 1, 'sits': 1, 'sofa': 1, 'the': 2})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# Convert documents to counter.\n",
    "docs_counter = [collections.Counter(doc.split()) for doc in docs]\n",
    "\n",
    "docs_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'on', 'sits', 'sofa', 'table', 'the'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Create unique term set.\n",
    "terms = set(itertools.chain.from_iterable(docs_counter))\n",
    "\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Create term-frequency function.\n",
    "def tf(t, d):\n",
    "    \"\"\"Calculates term-frequency for term t in document d.\"\"\"\n",
    "\n",
    "    # If term in document, return frequency. Else, return null:\n",
    "    if t in d.keys():\n",
    "        return d[t]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(tf('cat', docs_counter[0]))\n",
    "print(tf('cat', docs_counter[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cat': 0, 'dog': 1, 'on': 1, 'sits': 1, 'sofa': 0, 'table': 1, 'the': 2},\n",
       " {'cat': 1, 'dog': 0, 'on': 1, 'sits': 1, 'sofa': 1, 'table': 0, 'the': 2}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate term-frequency matrix.\n",
    "tf_matrix = [{t:tf(t, d) for t in terms} for d in docs_counter]\n",
    "\n",
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Create inverse document-frequency function.\n",
    "def idf(t, D):\n",
    "    \"\"\"Calculates inverse document-frequency for term t in documents D.\"\"\"\n",
    "    return math.log(len(D) / len([d for d in D if t in d.keys()]),2)\n",
    "\n",
    "print(idf('the', docs_counter))\n",
    "print(idf('cat', docs_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 1.0,\n",
       " 'dog': 1.0,\n",
       " 'on': 0.0,\n",
       " 'sits': 0.0,\n",
       " 'sofa': 1.0,\n",
       " 'table': 1.0,\n",
       " 'the': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate inverse document-frequency vector.\n",
    "idf_vector = {t: idf(t, docs_counter) for t in terms}\n",
    "\n",
    "idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cat': 0.0,\n",
       "  'dog': 0.0,\n",
       "  'on': 0.0,\n",
       "  'sits': 0.0,\n",
       "  'sofa': 0.0,\n",
       "  'table': 0.0,\n",
       "  'the': 0.6931471805599453},\n",
       " {'cat': 0.0,\n",
       "  'dog': 0.0,\n",
       "  'on': 0.0,\n",
       "  'sits': 0.0,\n",
       "  'sofa': 0.0,\n",
       "  'table': 0.0,\n",
       "  'the': 0.6931471805599453}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate term-frequency inverse document-frequency matrix.\n",
    "tfidf_matrix = [{t: tf_vector[t]*idf_vector[t] for t in terms} for tf_vector in tf_matrix]\n",
    "\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# Label term-frequency columns.\n",
    "tf_cols = ['tf_' + str(i + 1) for i in range(len(tf_matrix))]\n",
    "\n",
    "# Labels term-frequency inverse-document-frequency columns.\n",
    "tfidf_cols = ['tfidf_' + str(i + 1) for i in range(len(tfidf_matrix))]\n",
    "\n",
    "# Create function to build pandas data frame.\n",
    "def create_df(tf_matrix, idf_vector, tfidf_matrix, tf_cols, tfidf_cols):\n",
    "    # Create data frame dictionary.\n",
    "    df_dict = {}\n",
    "\n",
    "    # Fill data frame dictionary.\n",
    "    for tf_col, tf_vector in zip(tf_cols, tf_matrix): df_dict[tf_col] = tf_vector\n",
    "    df_dict['idf'] = idf_vector\n",
    "    for tfidf_col, tfidf_vector in zip(tfidf_cols, tfidf_matrix): df_dict[tfidf_col] = tfidf_vector\n",
    "\n",
    "    # Create column order.\n",
    "    col_order = []\n",
    "    col_order.extend(tf_cols)\n",
    "    col_order.append('idf')\n",
    "    col_order.extend(tfidf_cols)\n",
    "\n",
    "    # Create data frame and order by column order.\n",
    "    df = pandas.DataFrame.from_dict(df_dict)\n",
    "    df = df[col_order]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard TF-IDF\n",
      "\n",
      "       tf_1  tf_2  idf  tfidf_1  tfidf_2\n",
      "cat       0     1  1.0      0.0      1.0\n",
      "dog       1     0  1.0      1.0      0.0\n",
      "on        1     1  0.0      0.0      0.0\n",
      "sits      1     1  0.0      0.0      0.0\n",
      "sofa      0     1  1.0      0.0      1.0\n",
      "table     1     0  1.0      1.0      0.0\n",
      "the       2     2  0.0      0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "# Print data frame.\n",
    "print('Standard TF-IDF\\n')\n",
    "print(create_df(tf_matrix, idf_vector, tfidf_matrix, tf_cols, tfidf_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-linear term-frequency.\n",
    "def tf(t, d, sub_linear=False):\n",
    "    \"\"\"Calculates term-frequency for term t in document d.\"\"\"\n",
    "\n",
    "    # If term in document, return frequency. Else, return null:\n",
    "    if t in d.keys():\n",
    "        # If sub_linear, return log of tf.\n",
    "        if sub_linear:\n",
    "            return math.log(d[t]) + 1\n",
    "        else:\n",
    "            return d[t]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Linear TF-IDF\n",
      "\n",
      "           tf_1      tf_2       idf   tfidf_1   tfidf_2\n",
      "cat    0.000000  0.000000  1.584963  0.000000  0.000000\n",
      "dog    0.000000  0.000000  1.584963  0.000000  0.000000\n",
      "on     0.000000  0.000000  1.000000  0.000000  0.000000\n",
      "sits   0.000000  0.000000  1.000000  0.000000  0.000000\n",
      "sofa   0.000000  0.000000  1.584963  0.000000  0.000000\n",
      "table  0.000000  0.000000  1.584963  0.000000  0.000000\n",
      "the    0.693147  0.693147  1.000000  0.693147  0.693147\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = [{t:tf(t, d, sub_linear=True) for t in terms} for d in docs_counter]\n",
    "tfidf_matrix = [{t: tf_vector[t] * idf_vector[t] for t in terms} for tf_vector in tf_matrix]\n",
    "\n",
    "print('Sub-Linear TF-IDF\\n')\n",
    "print(create_df(tf_matrix, idf_vector, tfidf_matrix, tf_cols, tfidf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoother for inverse document-frequency.\n",
    "def idf(t, D, smoother=False):\n",
    "    \"\"\"Calculates inverse document-frequency for term t in documents D.\"\"\"\n",
    "\n",
    "    val = len(D) / len([d for d in D if t in d.keys()])\n",
    "\n",
    "    # If smoother, add 1 to val\n",
    "    if smoother:\n",
    "        val += 1\n",
    "    return math.log(val, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoother TF-IDF\n",
      "\n",
      "           tf_1      tf_2       idf   tfidf_1   tfidf_2\n",
      "cat    0.000000  0.353553  1.584963  0.000000  0.560369\n",
      "dog    0.353553  0.000000  1.584963  0.560369  0.000000\n",
      "on     0.353553  0.353553  1.000000  0.353553  0.353553\n",
      "sits   0.353553  0.353553  1.000000  0.353553  0.353553\n",
      "sofa   0.000000  0.353553  1.584963  0.000000  0.560369\n",
      "table  0.353553  0.000000  1.584963  0.560369  0.000000\n",
      "the    0.707107  0.707107  1.000000  0.707107  0.707107\n"
     ]
    }
   ],
   "source": [
    "idf_vector = {t: idf(t, docs_counter, True) for t in terms}\n",
    "tfidf_matrix = [{t: tf_vector[t] * idf_vector[t] for t in terms} for tf_vector in tf_matrix]\n",
    "\n",
    "print('Smoother TF-IDF\\n')\n",
    "print(create_df(tf_matrix, idf_vector, tfidf_matrix, tf_cols, tfidf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# Normalizing term-frequency.\n",
    "def tf(t, d, sub_linear=False, normalization=None):\n",
    "    \"\"\"Calculates term-frequency for term t in document d.\"\"\"\n",
    "\n",
    "    # If normalization is in ['l1', 'l2'], apply normalization.\n",
    "    if normalization in ['l1', 'l2']:\n",
    "        # If normalization is 'l1', apply l1 normalization.\n",
    "        if normalization == 'l1':\n",
    "            normalizer = numpy.sum(numpy.abs(list(d.values())))\n",
    "        # If normalization is 'l2', apply l2 normalization.\n",
    "        if normalization == 'l2':\n",
    "            normalizer = numpy.sqrt(numpy.sum(numpy.square(list(d.values()))))\n",
    "        d_norm = {word: d[word] / normalizer for word in d.keys()}\n",
    "    else:\n",
    "        d_norm = d\n",
    "\n",
    "    # If term in document, return frequency. Else, return null:\n",
    "    if t in d_norm.keys():\n",
    "        # If sub_linear, return log of tf.\n",
    "        if sub_linear:\n",
    "            return math.log(d_norm[t])\n",
    "        else:\n",
    "            return d_norm[t]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 TF-IDF\n",
      "\n",
      "           tf_1      tf_2       idf   tfidf_1   tfidf_2\n",
      "cat    0.000000  0.166667  1.584963  0.000000  0.264160\n",
      "dog    0.166667  0.000000  1.584963  0.264160  0.000000\n",
      "on     0.166667  0.166667  1.000000  0.166667  0.166667\n",
      "sits   0.166667  0.166667  1.000000  0.166667  0.166667\n",
      "sofa   0.000000  0.166667  1.584963  0.000000  0.264160\n",
      "table  0.166667  0.000000  1.584963  0.264160  0.000000\n",
      "the    0.333333  0.333333  1.000000  0.333333  0.333333\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = [{t:tf(t, d, False, 'l1') for t in terms} for d in docs_counter]\n",
    "tfidf_matrix = [{t: tf_vector[t] * idf_vector[t] for t in terms} for tf_vector in tf_matrix]\n",
    "\n",
    "print('L1 TF-IDF\\n')\n",
    "print(create_df(tf_matrix, idf_vector, tfidf_matrix, tf_cols, tfidf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 TF-IDF\n",
      "\n",
      "           tf_1      tf_2       idf   tfidf_1   tfidf_2\n",
      "cat    0.000000  0.353553  1.584963  0.000000  0.560369\n",
      "dog    0.353553  0.000000  1.584963  0.560369  0.000000\n",
      "on     0.353553  0.353553  1.000000  0.353553  0.353553\n",
      "sits   0.353553  0.353553  1.000000  0.353553  0.353553\n",
      "sofa   0.000000  0.353553  1.584963  0.000000  0.560369\n",
      "table  0.353553  0.000000  1.584963  0.560369  0.000000\n",
      "the    0.707107  0.707107  1.000000  0.707107  0.707107\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = [{t:tf(t, d, False, 'l2') for t in terms} for d in docs_counter]\n",
    "tfidf_matrix = [{t: tf_vector[t] * idf_vector[t] for t in terms} for tf_vector in tf_matrix]\n",
    "\n",
    "print('L2 TF-IDF\\n')\n",
    "print(create_df(tf_matrix, idf_vector, tfidf_matrix, tf_cols, tfidf_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.7071067811865475), (3, 0.7071067811865475)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "docs_tokenized = [d.split() for d in docs]\n",
    "\n",
    "dct = Dictionary(docs_tokenized)  # fit dictionary\n",
    "corpus = [dct.doc2bow(line) for line in docs_tokenized]  # convert dataset to BoW format\n",
    "\n",
    "model = TfidfModel(corpus)  # fit model\n",
    "vector = model[corpus[0]]  # apply model\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "Useful resources:  \n",
    "https://www.youtube.com/watch?v=P5mlg91as1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Matrix\n",
      "\n",
      "   alien  amelie  casablanca  matrix  serenity\n",
      "0      1       0           0       1         1\n",
      "1      3       0           0       3         3\n",
      "2      4       0           0       4         4\n",
      "3      5       0           0       5         5\n",
      "4      2       4           4       0         0\n",
      "5      0       5           5       0         0\n",
      "6      1       2           2       0         0\n"
     ]
    }
   ],
   "source": [
    "movie_dict = {'matrix': [1, 3, 4, 5, 0, 0, 0],\n",
    "                'alien': [1, 3, 4, 5, 2, 0, 1],\n",
    "                'serenity': [1, 3, 4, 5, 0, 0, 0],\n",
    "                'casablanca': [0, 0, 0, 0, 4, 5, 2],\n",
    "                'amelie': [0, 0, 0, 0, 4, 5, 2]}\n",
    "\n",
    "movie_matrix = pandas.DataFrame.from_dict(movie_dict)\n",
    "\n",
    "print('\\n\\nOriginal Matrix\\n')\n",
    "print(movie_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Features\n",
      "\n",
      "          0         1\n",
      "0  1.717377 -0.224512\n",
      "1  5.152130 -0.673537\n",
      "2  6.869507 -0.898049\n",
      "3  8.586884 -1.122561\n",
      "4  1.906788  5.620551\n",
      "5  0.901335  6.953762\n",
      "6  0.953394  2.810275\n",
      "\n",
      "\n",
      "SVD Singular Values\n",
      "\n",
      "           0\n",
      "0  12.481015\n",
      "1   9.508614\n",
      "\n",
      "\n",
      "SVD Components\n",
      "\n",
      "          0         1         2         3         4\n",
      "0  0.592860  0.090134  0.090134  0.562258  0.562258\n",
      "1  0.028771  0.695376  0.695376 -0.126641 -0.126641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=2)\n",
    "svd_features = svd_model.fit_transform(movie_matrix)\n",
    "\n",
    "print('SVD Features\\n')\n",
    "print(pandas.DataFrame(svd_features))\n",
    "\n",
    "print('\\n\\nSVD Singular Values\\n')\n",
    "print(pandas.DataFrame(svd_model.singular_values_))\n",
    "\n",
    "print('\\n\\nSVD Components\\n')\n",
    "print(pandas.DataFrame(svd_model.components_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing\n",
    "Useful resources:  \n",
    "https://www.youtube.com/watch?v=BJ0MnawUpaU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0             1\n",
      "term                             \n",
      "dog    7.071068e-01 -5.551115e-17\n",
      "on     1.098401e-16  2.505618e-16\n",
      "sits  -1.971561e-32 -4.667493e-32\n",
      "table  7.071068e-01  9.340158e-34\n",
      "the   -1.756232e-34 -6.162976e-33\n",
      "cat    3.988556e-17  7.071068e-01\n",
      "sofa   7.113675e-17  7.071068e-01\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "dictionary = corpora.Dictionary(docs_tokenized)\n",
    "# print(dictionary.token2id)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in docs_tokenized]\n",
    "# print(corpus)\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "total_topics = 2\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf,\n",
    "                      id2word=dictionary,\n",
    "                      num_topics=total_topics)\n",
    "\n",
    "pandas.DataFrame(lsi.print_topics(total_topics))\n",
    "\n",
    "df = pandas.DataFrame(lsi.projection.u)\n",
    "df['term'] = lsi.id2word.id2token.values()\n",
    "df = df.set_index('term')\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LDA Features\n",
      "\n",
      "          0         1\n",
      "0  0.794225  0.205775\n",
      "1  0.907556  0.092444\n",
      "2  0.927545  0.072455\n",
      "3  0.940429  0.059571\n",
      "4  0.111079  0.888921\n",
      "5  0.078317  0.921683\n",
      "6  0.179559  0.820441\n",
      "\n",
      "\n",
      "LDA Components\n",
      "\n",
      "          0         1         2         3         4\n",
      "0  0.309027  0.019400  0.019045  0.297667  0.301750\n",
      "1  0.114258  0.376663  0.376310  0.031118  0.024058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\Anaconda3\\envs\\text_analytics\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=2, doc_topic_prior=0.9, topic_word_prior=0.9)\n",
    "lda_features = lda_model.fit_transform(movie_matrix)\n",
    "\n",
    "print('\\n\\nLDA Features\\n')\n",
    "print(pandas.DataFrame(lda_features))\n",
    "\n",
    "print('\\n\\nLDA Components\\n')\n",
    "print(pandas.DataFrame(lda_model.exp_dirichlet_component_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
